{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios ensembling\n",
    "En este ejercicio vas a realizar prediciones sobre un dataset de ciudadanos indios diabéticos. Se trata de un problema de clasificación en el que intentaremos predecir 1 (diabético) 0 (no diabético)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga las librerias que consideres comunes al notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lee los datos de [esta direccion](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
    "Los nombres de columnas son:\n",
    "```Python\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   preg    768 non-null    int64  \n",
      " 1   plas    768 non-null    int64  \n",
      " 2   pres    768 non-null    int64  \n",
      " 3   skin    768 non-null    int64  \n",
      " 4   test    768 non-null    int64  \n",
      " 5   mass    768 non-null    float64\n",
      " 6   pedi    768 non-null    float64\n",
      " 7   age     768 non-null    int64  \n",
      " 8   class   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "preg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "plas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pres",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "test",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mass",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pedi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0f8a8cb4-fd77-4e75-ac43-dc93c8a1ce62",
       "rows": [
        [
         "0",
         "6",
         "148",
         "72",
         "35",
         "0",
         "33.6",
         "0.627",
         "50",
         "1"
        ],
        [
         "1",
         "1",
         "85",
         "66",
         "29",
         "0",
         "26.6",
         "0.351",
         "31",
         "0"
        ],
        [
         "2",
         "8",
         "183",
         "64",
         "0",
         "0",
         "23.3",
         "0.672",
         "32",
         "1"
        ],
        [
         "3",
         "1",
         "89",
         "66",
         "23",
         "94",
         "28.1",
         "0.167",
         "21",
         "0"
        ],
        [
         "4",
         "0",
         "137",
         "40",
         "35",
         "168",
         "43.1",
         "2.288",
         "33",
         "1"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']]\n",
    "y = df['class']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bagging\n",
    "Para este apartado tendrás que crear un ensemble utilizando la técnica de bagging ([BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)), mediante la cual combinarás 100 [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Recuerda utilizar también [cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) con 10 kfolds.\n",
    "\n",
    "**Para este apartado y siguientes, no hace falta que dividas en train/test**, por hacerlo más sencillo. Simplemente divide tus datos en features y target.\n",
    "\n",
    "Establece una semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth=5,random_state=42)\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    estimator = estimator,\n",
    "    n_estimators=100, # Cantidad de árboles\n",
    "    max_samples=100, # Muestras utilizadas en bootstrapping\n",
    "    bootstrap=True, # Usamos bootstrapping: muestreo con reemplazo.\n",
    "    max_features = 3, # Features que utiliza en el bootstrapping. Cuanto más bajo, mejor generalizará y menos overfitting\n",
    "    random_state=42)\n",
    "\n",
    "# bag_clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state=42,shuffle=True) #partimos los datos\n",
    "\n",
    "result_cv = model_selection.cross_val_score(bag_clf,X,y, cv=kfold, scoring='accuracy' )\n",
    "\n",
    "print(f\"Puntuaciones de validación cruzada: {result_cv}\")\n",
    "print(f\"Precisión media: {result_cv.mean():.4f} ± {result_cv.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest\n",
    "En este caso entrena un [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) con 100 árboles y un `max_features` de 3. También con validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100,\n",
    "                                 max_features=3,\n",
    "                                 random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state=42,shuffle=True) #partimos los datos\n",
    "\n",
    "result_cv = model_selection.cross_val_score(rnd_clf,X,y, cv=kfold, scoring='accuracy' )\n",
    "\n",
    "print(f\"Puntuaciones de validación cruzada: {result_cv}\")\n",
    "print(f\"Precisión media: {result_cv.mean():.4f} ± {result_cv.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. AdaBoost\n",
    "Implementa un [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) con 30 árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(estimator = estimator,\n",
    "                             n_estimators=30,\n",
    "                             learning_rate=0.5,\n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state=42,shuffle=True) #partimos los datos\n",
    "\n",
    "result_cv = model_selection.cross_val_score(ada_clf,X,y, cv=kfold, scoring='accuracy' )\n",
    "\n",
    "print(f\"Puntuaciones de validación cruzada: {result_cv}\")\n",
    "print(f\"Precisión media: {result_cv.mean():.4f} ± {result_cv.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GradientBoosting\n",
    "Implementa un [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) con 100 estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbct = GradientBoostingClassifier(max_depth=10,\n",
    "                                 n_estimators=100,\n",
    "                                 learning_rate=1.0,\n",
    "                                 random_state=42)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state=42,shuffle=True) #partimos los datos\n",
    "\n",
    "result_cv = model_selection.cross_val_score(gbct,X,y, cv=kfold, scoring='accuracy' )\n",
    "\n",
    "print(f\"Puntuaciones de validación cruzada: {result_cv}\")\n",
    "print(f\"Precisión media: {result_cv.mean():.4f} ± {result_cv.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. XGBoost\n",
    "Para este apartado utiliza un [XGBoostClassifier](https://docs.getml.com/latest/api/getml.predictors.XGBoostClassifier.html) con 100 estimadores. XGBoost no forma parte de la suite de modelos de sklearn, por lo que tendrás que instalarlo con pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_clas = xgboost.XGBClassifier(random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits = 10, random_state=42,shuffle=True) #partimos los datos\n",
    "\n",
    "result_cv = model_selection.cross_val_score(xgb_clas,X,y, cv=kfold, scoring='accuracy' )\n",
    "\n",
    "print(f\"Puntuaciones de validación cruzada: {result_cv}\")\n",
    "print(f\"Precisión media: {result_cv.mean():.4f} ± {result_cv.std():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Primeros resultados\n",
    "Crea un dataframe con los resultados y sus algoritmos, ordenándolos de mayor a menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [bag_clf,rnd_clf,ada_clf, gbct,xgb_clas]\n",
    "medias = []\n",
    "for modelo in modelos:\n",
    "    result_cv = model_selection.cross_val_score(modelo,X,y, cv=kfold, scoring='accuracy' )\n",
    "    medias.append(result_cv.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos={\n",
    "    'modelos': ['bag_clf','rnd_clf','ada_clf', 'gbct','xgb_clas'],\n",
    "    'media': medias    \n",
    "}\n",
    "\n",
    "resultados =  pd.DataFrame(datos)\n",
    "resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Hiperparametrización\n",
    "Vuelve a entrenar los modelos de nuevo, pero esta vez dividiendo el conjunto de datos en train/test y utilizando un gridsearch para encontrar los mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# modelo bag_clf\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 100, 200],\n",
    "    'max_samples': [100,150,200],# número de muestras\n",
    "    'max_features': [4,6,8], # número de columnas que tiene que tener en cuenta\n",
    "    'estimator__max_depth':[2,3,4,5],\n",
    "    'estimator__min_samples_split':[3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bag_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross validation\n",
    "    scoring='accuracy',      # Métrica a optimizar\n",
    "    n_jobs=-1,              # Usar todos los cores del CPU\n",
    "    verbose=2               # Mostrar progreso detallado\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación: {grid_search.best_score_:.4f}\")\n",
    "best_model_bag_clf = grid_search.best_estimator_\n",
    "best_model_bag_clf_score = grid_search.best_score_\n",
    "\n",
    "#Evaluo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# modelo rnd_clf\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 100, 200],\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'max_features': [3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rnd_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross validation\n",
    "    scoring='accuracy',      # Métrica a optimizar\n",
    "    n_jobs=-1,              # Usar todos los cores del CPU\n",
    "    verbose=2               # Mostrar progreso detallado\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación: {grid_search.best_score_:.4f}\")\n",
    "best_model_rnd_clf = grid_search.best_estimator_\n",
    "best_model_rnd_clf_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modelo ada_clf\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 70,40],\n",
    "    'learning_rate': [1.25, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross validation\n",
    "    scoring='accuracy',      # Métrica a optimizar\n",
    "    n_jobs=-1,              # Usar todos los cores del CPU\n",
    "    verbose=2               # Mostrar progreso detallado\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación: {grid_search.best_score_:.4f}\")\n",
    "best_model_ada_clf = grid_search.best_estimator_\n",
    "best_model_ada_clf_score = grid_search.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modelo gbct\n",
    "param_grid = {\n",
    "    'n_estimators': [75, 100, 150],\n",
    "    'learning_rate': [0.1, 0.25, 0.5],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "    'min_samples_leaf': [7, 5,3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gbct,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross validation\n",
    "    scoring='accuracy',      # Métrica a optimizar\n",
    "    n_jobs=-1,              # Usar todos los cores del CPU\n",
    "    verbose=2               # Mostrar progreso detallado\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación: {grid_search.best_score_:.4f}\")\n",
    "best_model_gbct = grid_search.best_estimator_\n",
    "best_model_gbct_score = grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo XGboost\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [30,50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    'max_depth': [3,4, 5,6, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_clas,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross validation\n",
    "    scoring='accuracy',      # Métrica a optimizar\n",
    "    n_jobs=-1,              # Usar todos los cores del CPU\n",
    "    verbose=2               # Mostrar progreso detallado\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación: {grid_search.best_score_:.4f}\")\n",
    "best_model_xgb_clas = grid_search.best_estimator_\n",
    "best_model_xgb_clas_score = grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_modelos = ['best_model_bag_clf','best_model_rnd_clf', 'best_model_ada_clf', 'best_model_gbct', 'best_model_xgb_clas']\n",
    "best_scores = [best_model_bag_clf_score,best_model_rnd_clf_score, best_model_ada_clf_score, best_model_gbct_score, best_model_xgb_clas_score]\n",
    "\n",
    "\n",
    "datos_best={\n",
    "    'mejores_modelos': ['best_model_bag_clf','best_model_rnd_clf', 'best_model_ada_clf', 'best_model_gbct', 'best_model_xgb_clas'],\n",
    "    'best_scores': best_scores   \n",
    "}\n",
    "\n",
    "resultados =  pd.DataFrame(datos_best)\n",
    "resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Conclusiones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según mis datos el mejor es el RND_CLF, se depende de los parametros para poder estimar bien un modelo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
